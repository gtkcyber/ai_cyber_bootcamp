{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/GTK_Logo_Social Icon.jpg\" width=175 align=\"right\" />\n",
    "\n",
    "# Worksheet 5.3: Tuning your Classifier - Answers\n",
    "This worksheet covers concepts relating to tuning a classifier.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (https://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Scikit-learn (https://scikit-learn.org/stable/documentation.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:04.428938Z",
     "start_time": "2025-07-22T18:34:03.473173Z"
    }
   },
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform as sp_rand\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "For this exercise, we are going to focus on building a pipeline and then tuning the resultant model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:08.823545Z",
     "start_time": "2025-07-22T18:34:08.802094Z"
    }
   },
   "source": [
    "df_final = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "target = df_final['isDGA']\n",
    "feature_matrix = df_final.drop(['isDGA'], axis=1)\n",
    "feature_matrix.sample(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      length  digits   entropy  vowel-cons  firstDigitIndex       ngrams\n",
       "780       12       0  3.251629    0.090909                0   591.538384\n",
       "769       14       0  3.324863    0.166667                0   671.736874\n",
       "1015       9       0  2.725481    0.500000                0  1715.027116\n",
       "652       20       0  3.784184    0.250000                0   875.422807\n",
       "682       26       9  3.738149    0.000000                4   410.416410"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>firstDigitIndex</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1544.366402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.121928</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1304.036111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1188.501323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3.189898</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>996.605617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921928</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>1110.353704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  digits   entropy  vowel-cons  firstDigitIndex       ngrams\n",
       "1672       9       0  3.169925    0.500000                0  1544.366402\n",
       "982       10       0  3.121928    0.666667                0  1304.036111\n",
       "67         9       0  3.169925    0.500000                0  1188.501323\n",
       "404       15       0  3.189898    0.363636                0   996.605617\n",
       "1123      10       0  2.921928    0.428571                0  1110.353704"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "target = df_final['isDGA']\n",
    "feature_matrix = df_final.drop(['isDGA'], axis='columns')\n",
    "feature_matrix.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets.\n",
    "We're going to need a training and testing dataset, so you know the drill, split the data.."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:10.654510Z",
     "start_time": "2025-07-22T18:34:10.650417Z"
    }
   },
   "source": [
    "feature_matrix_train, feature_matrix_test, target_train, target_test = train_test_split(feature_matrix, \n",
    "                                                                                        target, \n",
    "                                                                                        test_size=0.25)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "For this exercise, we're going to create a K-NN Classifier for the DGA data and tune it.   (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) \n",
    "\n",
    "\n",
    "1. Create a classifier with the default options (leave the arguments blank and they will use the deafults). \n",
    "2. Train the classifier on the training data\n",
    "3. Calculate the accuracy score for the model based on the test data.\n",
    "\n",
    "\n",
    "The sklearn default values for the KNeighborsClassifier hyperparameters are shown below.\n",
    "```python \n",
    "KNeighborsClassifier(algorithm='auto', \n",
    "                     leaf_size=30, \n",
    "                     metric='minkowski',\n",
    "                     metric_params=None, \n",
    "                     n_jobs=1, \n",
    "                     n_neighbors=5, \n",
    "                     p=2,\n",
    "                     weights='uniform')\n",
    "```           "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:12.653929Z",
     "start_time": "2025-07-22T18:34:12.644874Z"
    }
   },
   "source": [
    "# Your code here ...\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit( feature_matrix_train, target_train )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create\n",
    "knn_model = KNeighborsClassifier()\n",
    "#train\n",
    "knn_model.fit( feature_matrix_train, target_train )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:13.265862Z",
     "start_time": "2025-07-22T18:34:13.253972Z"
    }
   },
   "source": [
    "#predict\n",
    "default_predictions = knn_model.predict(feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:14.194335Z",
     "start_time": "2025-07-22T18:34:14.189313Z"
    }
   },
   "source": [
    "accuracy_score( target_test, default_predictions)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metric\n",
    "accuracy_score(target_test, default_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filename = '../data/dga_model.sav'\n",
    "pickle.dump(knn_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance \n",
    "The model achieves approximately 85% accuracy when we use the default parameters.  It is significantly better than chance (50%) but let's see if we can do better. \n",
    "\n",
    "**Note:  This notebook is written without using fixed random seeds, so you might get slightly different results.**\n",
    "\n",
    "### Scaling the Features (preprocessing)\n",
    "K-NN is a distance-based classifier and hence it is necessary to scale the features prior to training the model.  \n",
    "\n",
    "### Create Pipeline\n",
    "Pipeline allows you to sequentially apply a list of transformers to preprocess the data and, if desired, conclude the sequence with a final predictor for predictive modeling.  Let's create a simple pipeline with two steps:\n",
    "\n",
    "1.  StandardScaler\n",
    "2.  Train the classifier\n",
    "\n",
    "Once you've done that, calculate the accuracy and see if it has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:19.117488Z",
     "start_time": "2025-07-22T18:34:19.108480Z"
    }
   },
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(feature_matrix_train, target_train )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_knn = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('knn_model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_knn.fit(feature_matrix_train, target_train ).score(feature_matrix_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the features did result in a small improvement: .85 accuracy to .88.  But let's see if we can't do even better.\n",
    "\n",
    "### Using RandomSearchCV and GridSearchCV to tune Hyperparameters\n",
    "Now that we've scaled the features and built a simple pipeline, let's try to tune the hyperparameters to see if we can improve the model performance.  Scikit-learn provides two methods for accomplishing this task: `RandomizedSearchCV` and `GridSearchCV`. \n",
    "\n",
    "\n",
    "* `GridSearchCV`:  GridSearch iterates through all possible combinations of tuning parameters to find the optimal combination. (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "* `RandomizedSearchCV`:  RandomizedSearch interates through random combinations of paremeters to find the optimal combination.  While RandomizedSearch does not try every possible combination, is considerably faster than GridSearch and has been shown to get very close to the optimal combination in considerably less time.  (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) \n",
    "\n",
    "Both `RandomizedSearchCV` and `GridSearchCV` require you to provide a grid of parameters.  You will need to refer to the documentation for the classifier you are using to get a list of paramenters for that particular model.  Also since we will be using the pipeline, you have to format the parameters correctly.  The name of the variable must be preceeded by the name of the step in your pipeline and two underscores.  For example.  If the classifier in the pipeline is called `knn_model`, and you have a tuning parameter called `metric`, the parameter grid would be as follows:\n",
    "```python\n",
    "params = {\n",
    "    \"knn_model__n_neighbors\": np.arange(1, 50, 2),\n",
    "    \"knn_model__metric\": [\"euclidean\", \"cityblock\"] \n",
    "}\n",
    "```\n",
    "### Your Task\n",
    "Using RandomizedSearchCV, improve the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:33.081655Z",
     "start_time": "2025-07-22T18:34:24.014907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 11.30 seconds\n",
      "[INFO] grid search accuracy: 90.33%\n",
      "[INFO] randomized search best parameters: {'knn_model__weights': 'uniform', 'knn_model__p': 1, 'knn_model__n_neighbors': 35, 'knn_model__metric': 'manhattan', 'knn_model__leaf_size': 9, 'knn_model__algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "params = {\"knn_model__n_neighbors\": np.arange(1, 50, 2), \n",
    "         \"knn_model__weights\": [\"uniform\", \"distance\"],\n",
    "         \"knn_model__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "         \"knn_model__leaf_size\": np.arange(1, 80, 2),\n",
    "         \"knn_model__p\": [1,2],\n",
    "         \"knn_model__metric\": [\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline_knn, params, n_iter=100)\n",
    "start = time.time()\n",
    "grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the test data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "acc = grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(grid.best_params_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 9.06 seconds\n",
      "[INFO] grid search accuracy: 91.53%\n",
      "[INFO] randomized search best parameters: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 19, 'clf__metric': 'manhattan', 'clf__leaf_size': 65, 'clf__algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model was able to achieve an improved accuracy with RandomSearch!   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Your final task is to:\n",
    "1.  Using RandomForest, create a classifier for the DGA dataset\n",
    "2.  Use either GridSearchCV or RandomizedSearchCV to find the optimal parameters for this model.\n",
    "\n",
    "How does this model compare with the first K-NN classifier for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:34:49.980716Z",
     "start_time": "2025-07-22T18:34:47.009198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 13.35 seconds\n",
      "[INFO] grid search accuracy: 90.67%\n",
      "[INFO] randomized search best parameters: {'n_estimators': 251, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(1, 400, 50),\n",
    "    \"max_features\": ['auto', 'sqrt','log2' ],\n",
    "    \"max_depth\": np.arange(1, 20, 2),\n",
    "    \"criterion\": ['gini','entropy']\n",
    "} \n",
    "\n",
    "rf_grid = RandomizedSearchCV(rf_clf, params )\n",
    "start = time.time()\n",
    "rf_grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#acc = grid.score(feature_matrix_test, target_test)\n",
    "acc = rf_grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(rf_grid.best_params_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 2.97 seconds\n",
      "[INFO] grid search accuracy: 91.80%\n",
      "[INFO] randomized search best parameters: {'n_estimators': 51, 'max_features': 'log2', 'max_depth': 5, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
